from mmengine.config import read_base

with read_base():
    # pylint: disable-next=E0402,W0401,W0614
    from .xview400_dataset_child import *  # noqa: F401,F403,W0401,W0614

# dataset settings - do not change, it should match up with the paths generated by
# enclave_scripts/scripts/slice_xview.sh, which is `data/xview/chipped/...` This should
# point to aic_det/data/, which should look like this:
#  (aic_det) ➜  dgx1:~/proj/aic_det/lib<main>tree ../data -L 4
# ../data
# └── xview
#     ├── chipped
#     │   ├── 2048_0
#     │   │   ├── xview_coco_full.json
#     │   │   ├── xview_coco_train_2048_0.json
#     │   │   ├── xview_coco_train_images_2048_0
#     │   │   ├── xview_coco_train.json
#     │   │   ├── xview_coco_val_2048_0.json
#     │   │   ├── xview_coco_val_images_2048_0
#     │   │   └── xview_coco_val.json
#     │   └── 400_0
#     │       ├── xview_coco_full.json
#     │       ├── xview_coco_train_400_0.json
#     │       ├── xview_coco_train_images_400_0
#     │       ├── xview_coco_train.json
#     │       ├── xview_coco_val_400_0.json
#     │       ├── xview_coco_val_images_400_0
#     │       └── xview_coco_val.json
data_root = "data/xview/chipped/200_0"


# define per gpu batch size here, lr and max-iter should will be scaled automatically.
train_dataloader.merge(
    dict(
        batch_size=4,
        num_workers=8,
        dataset=dict(
            data_root=data_root,
            ann_file="xview_coco_train_200_0_51classes-child_level.json",
            data_prefix=dict(img="xview_coco_train_images_200_0/"),
        ),
    )
)

val_dataloader.merge(
    dict(
        batch_size=8,
        num_workers=4,
        dataset=dict(
            data_root=data_root,
            ann_file="xview_coco_val_200_0_51classes-child_level.json",
            data_prefix=dict(img="xview_coco_val_images_200_0/"),
        ),
    )
)
